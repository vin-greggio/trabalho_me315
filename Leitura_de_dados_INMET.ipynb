{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6wR26QZ8W-n",
        "outputId": "263bb2c8-6e46-4ead-961f-b38595389837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/Banco com zip/'\n",
        "\n",
        "for year in range(2000, 2025):\n",
        "    zip_file_path = os.path.join(base_path, str(year) + '.zip')\n",
        "    if os.path.exists(zip_file_path):\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            extraction_path = os.path.join('diretorio_destino', str(year))\n",
        "            zip_ref.extractall(extraction_path)\n",
        "            print(f\"Files from {zip_file_path} extracted to {extraction_path}\")\n",
        "    else:\n",
        "        print(f\"Zip file not found for year {year}: {zip_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpSwsknz8hDo",
        "outputId": "6cc59ea3-08cf-4c54-e834-d2f4a5185570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file not found for year 2000: /content/drive/MyDrive/Banco com zip/2000.zip\n",
            "Zip file not found for year 2001: /content/drive/MyDrive/Banco com zip/2001.zip\n",
            "Zip file not found for year 2002: /content/drive/MyDrive/Banco com zip/2002.zip\n",
            "Zip file not found for year 2003: /content/drive/MyDrive/Banco com zip/2003.zip\n",
            "Zip file not found for year 2004: /content/drive/MyDrive/Banco com zip/2004.zip\n",
            "Zip file not found for year 2005: /content/drive/MyDrive/Banco com zip/2005.zip\n",
            "Zip file not found for year 2006: /content/drive/MyDrive/Banco com zip/2006.zip\n",
            "Zip file not found for year 2007: /content/drive/MyDrive/Banco com zip/2007.zip\n",
            "Zip file not found for year 2008: /content/drive/MyDrive/Banco com zip/2008.zip\n",
            "Zip file not found for year 2009: /content/drive/MyDrive/Banco com zip/2009.zip\n",
            "Zip file not found for year 2010: /content/drive/MyDrive/Banco com zip/2010.zip\n",
            "Zip file not found for year 2011: /content/drive/MyDrive/Banco com zip/2011.zip\n",
            "Zip file not found for year 2012: /content/drive/MyDrive/Banco com zip/2012.zip\n",
            "Zip file not found for year 2013: /content/drive/MyDrive/Banco com zip/2013.zip\n",
            "Zip file not found for year 2014: /content/drive/MyDrive/Banco com zip/2014.zip\n",
            "Zip file not found for year 2015: /content/drive/MyDrive/Banco com zip/2015.zip\n",
            "Zip file not found for year 2016: /content/drive/MyDrive/Banco com zip/2016.zip\n",
            "Zip file not found for year 2017: /content/drive/MyDrive/Banco com zip/2017.zip\n",
            "Zip file not found for year 2018: /content/drive/MyDrive/Banco com zip/2018.zip\n",
            "Zip file not found for year 2019: /content/drive/MyDrive/Banco com zip/2019.zip\n",
            "Zip file not found for year 2020: /content/drive/MyDrive/Banco com zip/2020.zip\n",
            "Zip file not found for year 2021: /content/drive/MyDrive/Banco com zip/2021.zip\n",
            "Zip file not found for year 2022: /content/drive/MyDrive/Banco com zip/2022.zip\n",
            "Zip file not found for year 2023: /content/drive/MyDrive/Banco com zip/2023.zip\n",
            "Zip file not found for year 2024: /content/drive/MyDrive/Banco com zip/2024.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import polars as pl\n",
        "import sqlite3\n",
        "\n",
        "def map_polars_to_sql_type(polars_type):\n",
        "    if polars_type == pl.Int32 or polars_type == pl.Int64:\n",
        "        return \"INTEGER\"\n",
        "    elif polars_type == pl.Float32 or polars_type == pl.Float64:\n",
        "        return \"REAL\"\n",
        "    else:\n",
        "        return \"TEXT\"\n",
        "\n",
        "def processar_e_salvar_no_sql(ano, chunk_size=1000):\n",
        "    # conectando ao banco ",
        "    db_path = '/content/dados_anos.db'\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    diretorio_destino = f'/content/diretorio_destino/{ano}/{ano}' if ano < 2020 else f'/content/diretorio_destino/{ano}'\n",
        "\n",
        "    arquivos_csv = [f for f in os.listdir(diretorio_destino) if f.lower().endswith(\".csv\")]\n",
        "\n",
        "    tabela_criada = False  # Flag para garantir que a tabela seja criada apenas uma vez\n",
        "\n",
        "    for arquivo in arquivos_csv:\n",
        "        caminho_completo = os.path.join(diretorio_destino, arquivo)\n",
        "        estacao = arquivo.split('_')[3]\n",
        "\n",
        "        # Capturar as colunas e tipos\n",
        "        first_chunk = pl.read_csv(\n",
        "            caminho_completo,\n",
        "            skip_rows=8,\n",
        "            separator=\";\",\n",
        "            decimal_comma=True,\n",
        "            encoding=\"ISO-8859-1\",\n",
        "            infer_schema_length=10000\n",
        "        ).with_columns(pl.lit(estacao).alias(\"estacao\"))\n",
        "\n",
        "        colunas = first_chunk.columns\n",
        "        tipos = [map_polars_to_sql_type(dtype) for dtype in first_chunk.dtypes]\n",
        "\n",
        "        if not tabela_criada:\n",
        "            cursor.execute(f\"DROP TABLE IF EXISTS dados_{ano}\")\n",
        "\n",
        "            colunas_sql = \", \".join([f'\"{col}\" {tipo}' for col, tipo in zip(colunas, tipos)])\n",
        "            cursor.execute(f\"CREATE TABLE dados_{ano} ({colunas_sql})\")\n",
        "            conn.commit()\n",
        "            tabela_criada = True\n",
        "        for chunk_df in pl.read_csv(\n",
        "                caminho_completo,\n",
        "                skip_rows=8,\n",
        "                separator=\";\",\n",
        "                decimal_comma=True,\n",
        "                encoding=\"ISO-8859-1\",\n",
        "                infer_schema_length=10000,\n",
        "                ignore_errors=True,\n",
        "                null_values=\"-9999\",\n",
        "        ).iter_slices(chunk_size):\n",
        "            chunk_df = chunk_df.with_columns(pl.lit(estacao).alias(\"estacao\"))\n",
        "\n",
        "            registros = chunk_df.to_numpy().tolist()\n",
        "            placeholders = ', '.join(['?' for _ in colunas])\n",
        "\n",
        "            cursor.executemany(\n",
        "                f'INSERT INTO dados_{ano} VALUES ({placeholders})',\n",
        "                registros\n",
        "            )\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(f\"Dados do ano {ano} processados e salvos no banco de dados com sucesso!\")\n",
        "\n",
        "for ano in range(2000, 2025):\n",
        "    processar_e_salvar_no_sql(ano, chunk_size=1000)\n",
        "    print(f\"Data para o ano {ano} processada e armazenada com sucesso!\")\n"
      ],
      "metadata": {
        "id": "d5NxvXWwBAcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dZaP9DkGBJJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_path = '/content/dados_anos.db'\n",
        "conn = sqlite3.connect(db_path)"
      ],
      "metadata": {
        "id": "FfiFBVgYBMiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query(\"\"\"SELECT * FROM dados_2000\"\"\", conn)"
      ],
      "metadata": {
        "id": "LccuodvZBxI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query(\"\"\"SELECT \"DATA (YYYY-MM-DD)\", `HORA (UTC)`,`TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)`, estacao FROM dados_2000\n",
        "ORDER BY `TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)` DESC LIMIT 1\"\"\", conn)"
      ],
      "metadata": {
        "id": "MGL7TvnLBGJv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
